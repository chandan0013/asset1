{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the hawks dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\tweets_#gohawks.txt')\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_hawks_followers = []\n",
    "tweet_hawks_pdate = []\n",
    "tweet_hawks_rcount = []\n",
    "tweet_hawks_imp = []\n",
    "tweet_hawks_rank = []\n",
    "tweet_hawks_cite = []\n",
    "user_id_hawks = []\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_hawks_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_hawks_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_hawks_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_hawks_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_hawks_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_hawks_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_hawks.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "h,ind_hawks = np.unique(user_id_hawks,return_index=True)\n",
    "\n",
    "numtweets_hawks = len(tweet_hawks_followers)\n",
    "\n",
    "start_time_hawks = tweet_hawks_pdate[0]\n",
    "end_time_hawks = tweet_hawks_pdate[numtweets_hawks - 1]\n",
    "duration_hawks = (end_time_hawks - start_time_hawks)/3600\n",
    "\n",
    "num_followers_hawks = 0\n",
    "num_retweets_hawks = 0\n",
    "\n",
    "for i in range(0,numtweets_hawks - 1):\n",
    "        \n",
    "    num_retweets_hawks = num_retweets_hawks + tweet_hawks_rcount[i]\n",
    "    \n",
    "\n",
    "tweet_hawks_unique =  [tweet_hawks_followers[i] for i in ind_hawks]\n",
    "\n",
    "avg_num_tweets_hawks = numtweets_hawks / duration_hawks\n",
    "avg_num_followers_hawks = sum(tweet_hawks_unique) / len(h)\n",
    "avg_num_retweets_hawks = num_retweets_hawks / numtweets_hawks\n",
    "\n",
    "print(avg_num_tweets_hawks)\n",
    "print(avg_num_followers_hawks)\n",
    "print(avg_num_retweets_hawks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the gopatriots dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\tweets_#gopatriots.txt')\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_gp_followers = []\n",
    "tweet_gp_pdate = []\n",
    "tweet_gp_rcount = []\n",
    "tweet_gp_imp = []\n",
    "tweet_gp_rank = []\n",
    "tweet_gp_cite = []\n",
    "user_id_gp = []\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_gp_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_gp_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_gp_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_gp_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_gp_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_gp_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_gp.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtweets_gp = len(tweet_gp_followers)\n",
    "import numpy as np\n",
    "gp,ind_gp = np.unique(user_id_gp,return_index=True)\n",
    "\n",
    "\n",
    "\n",
    "start_time_gp = tweet_gp_pdate[0]\n",
    "end_time_gp = tweet_gp_pdate[numtweets_gp - 1]\n",
    "duration_gp = (end_time_gp - start_time_gp)/3600\n",
    "\n",
    "num_followers_gp = 0\n",
    "num_retweets_gp = 0\n",
    "\n",
    "for i in range(0,numtweets_gp - 1):\n",
    "    \n",
    "    num_retweets_gp = num_retweets_gp + tweet_gp_rcount[i]\n",
    "\n",
    "tweet_gp_unique =  [tweet_gp_followers[i] for i in ind_gp]\n",
    "avg_num_tweets_gp = numtweets_gp / duration_gp\n",
    "avg_num_followers_gp = sum(tweet_gp_unique) / len(gp) \n",
    "avg_num_retweets_gp = num_retweets_gp / numtweets_gp\n",
    "\n",
    "print(avg_num_tweets_gp)\n",
    "print(avg_num_followers_gp)\n",
    "print(avg_num_retweets_gp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the patriots dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('C:\\\\Users\\\\Chandan\\\\Desktop\\\\tweets_#patriots.txt')\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_p_followers = []\n",
    "tweet_p_pdate = []\n",
    "tweet_p_rcount = []\n",
    "tweet_p_imp = []\n",
    "tweet_p_rank = []\n",
    "tweet_p_cite = []\n",
    "user_id_p = []\n",
    "\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_p_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_p_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_p_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_p_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_p_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_p_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_p.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtweets_p = len(tweet_p_followers)\n",
    "import numpy as np\n",
    "p,ind_p = np.unique(user_id_p,return_index=True)\n",
    "\n",
    "\n",
    "\n",
    "start_time_p = tweet_p_pdate[0]\n",
    "end_time_p = tweet_p_pdate[numtweets_p - 1]\n",
    "duration_p = (end_time_p - start_time_p)/3600\n",
    "\n",
    "num_followers_p = 0\n",
    "num_retweets_p = 0\n",
    "\n",
    "for i in range(0,numtweets_p - 1):\n",
    "    \n",
    "    num_retweets_p = num_retweets_p + tweet_p_rcount[i]\n",
    "\n",
    "tweet_p_unique =  [tweet_p_followers[i] for i in ind_p]\n",
    "avg_num_tweets_p = numtweets_p / duration_p\n",
    "avg_num_followers_p = sum(tweet_p_unique) / len(p) \n",
    "avg_num_retweets_p = num_retweets_p / numtweets_p\n",
    "\n",
    "print(avg_num_tweets_p)\n",
    "print(avg_num_followers_p)\n",
    "print(avg_num_retweets_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the nfl dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('/Users/daffodil/Desktop/tweet_data/tweets_#nfl.txt')\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_n_followers = []\n",
    "tweet_n_pdate = []\n",
    "tweet_n_rcount = []\n",
    "tweet_n_imp = []\n",
    "tweet_n_rank = []\n",
    "tweet_n_cite = []\n",
    "user_id_n = []\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_n_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_n_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_n_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_n_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_n_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_n_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_n.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtweets_n = len(tweet_n_followers)\n",
    "import numpy as np\n",
    "n,ind_n = np.unique(user_id_n,return_index=True)\n",
    "\n",
    "start_time_n = tweet_n_pdate[0]\n",
    "end_time_n = tweet_n_pdate[numtweets_n - 1]\n",
    "duration_n = (end_time_n - start_time_n)/3600\n",
    "\n",
    "num_followers_n = 0\n",
    "num_retweets_n = 0\n",
    "\n",
    "for i in range(0,numtweets_n - 1):\n",
    "\n",
    "    num_retweets_n = num_retweets_n + tweet_n_rcount[i]\n",
    "\n",
    "tweet_n_unique =  [tweet_n_followers[i] for i in ind_n]\n",
    "avg_num_tweets_n = numtweets_n / duration_n\n",
    "avg_num_followers_n = sum(tweet_n_unique) / len(n) \n",
    "avg_num_retweets_n = num_retweets_n / numtweets_n\n",
    "\n",
    "print(avg_num_tweets_n)\n",
    "print(avg_num_followers_n)\n",
    "print(avg_num_retweets_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the sb49 dataset\n",
    "# Features imported are number of followers, posting date of the tweet, retweet count\n",
    "\n",
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('/Users/daffodil/Desktop/tweet_data/tweets_#sb49.txt')\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_sb_followers = []\n",
    "tweet_sb_pdate = []\n",
    "tweet_sb_rcount = []\n",
    "tweet_sb_imp = []\n",
    "tweet_sb_rank = []\n",
    "tweet_sb_cite = []\n",
    "user_id_sb = []\n",
    "\n",
    "\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_sb_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_sb_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_sb_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_sb_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_sb_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_sb_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_sb.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtweets_sb = len(tweet_sb_followers)\n",
    "import numpy as np\n",
    "sb,ind_sb = np.unique(user_id_sb,return_index=True)\n",
    "\n",
    "start_time_sb = tweet_sb_pdate[0]\n",
    "end_time_sb = tweet_sb_pdate[numtweets_sb - 1]\n",
    "duration_sb = (end_time_sb - start_time_sb)/3600\n",
    "\n",
    "num_followers_sb = 0\n",
    "num_retweets_sb = 0\n",
    "\n",
    "for i in range(0,numtweets_sb - 1):\n",
    "    \n",
    "    num_retweets_sb = num_retweets_sb + tweet_sb_rcount[i]\n",
    "\n",
    "tweet_sb_unique =  [tweet_sb_followers[i] for i in ind_sb]\n",
    "avg_num_tweets_sb = numtweets_sb / duration_sb\n",
    "avg_num_followers_sb = sum(tweet_sb_unique) / len(sb) \n",
    "avg_num_retweets_sb = num_retweets_sb / numtweets_sb\n",
    "\n",
    "print(avg_num_tweets_sb)\n",
    "print(avg_num_followers_sb)\n",
    "print(avg_num_retweets_sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime, time\n",
    "\n",
    "\n",
    "f = open('/Users/daffodil/Desktop/tweet_data/tweets_#superbowl.txt')\n",
    "\n",
    "line = f.readline()\n",
    "\n",
    "\n",
    "tweet_s_followers = []\n",
    "tweet_s_pdate = []\n",
    "tweet_s_rcount = []\n",
    "tweet_s_imp = []\n",
    "tweet_s_rank = []\n",
    "tweet_s_cite = []\n",
    "user_id_s = []\n",
    "\n",
    "\n",
    "\n",
    "while len(line)!=0:\n",
    "    tweet = json.loads(line)\n",
    "    tweet_s_followers.append(tweet['tweet']['user']['followers_count'])\n",
    "    tweet_s_pdate.append(tweet['firstpost_date'])\n",
    "    tweet_s_rcount.append(tweet['metrics']['citations']['total'])\n",
    "    tweet_s_imp.append(tweet['metrics']['impressions'])\n",
    "    tweet_s_rank.append(tweet['metrics']['ranking_score'])\n",
    "    tweet_s_cite.append(tweet['tweet']['retweet_count'])\n",
    "    user_id_s.append(tweet['tweet']['user']['id'])\n",
    "    line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numtweets_s = len(tweet_s_followers)\n",
    "import numpy as np\n",
    "s,ind_s = np.unique(user_id_s,return_index=True)\n",
    "\n",
    "start_time_s = tweet_s_pdate[0]\n",
    "end_time_s = tweet_s_pdate[numtweets_s - 1]\n",
    "duration_s = (end_time_s - start_time_s)/3600\n",
    "\n",
    "num_followers_s = 0\n",
    "num_retweets_s = 0\n",
    "\n",
    "for i in range(0,numtweets_s - 1):\n",
    "    \n",
    "    num_retweets_s = num_retweets_s + tweet_s_rcount[i]\n",
    "    \n",
    "\n",
    "tweet_s_unique =  [tweet_s_followers[i] for i in ind_s]\n",
    "avg_num_tweets_s = numtweets_s / duration_s\n",
    "avg_num_followers_s = sum(tweet_s_unique) / len(s) \n",
    "avg_num_retweets_s = num_retweets_s / numtweets_s\n",
    "\n",
    "print(avg_num_tweets_s)\n",
    "print(avg_num_followers_s)\n",
    "print(avg_num_retweets_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
